{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 4 Members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Shyam Akhil Nekkanti - 8982123\n",
    "* Jun He (Helena) - 8903073\n",
    "* Zheming Li (Brendan) - 8914152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field of Inquiry: **YouTube Video Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question: **What factors most significantly impact the views of a YouTube video?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " We analyzes YouTube video engagement metrics to predict video virality and optimize content strategies for creators. By examining features such as likes-to-views ratio, comments-to-views ratio, and video category, the goal is to identify patterns that correlate with a video trending.\n",
    "\n",
    " ### Revised Hypothesis:\n",
    "\"Videos with higher engagement ratios (likes and comments per view) are more likely to trend compared to videos with high view counts alone. Additionally, specific categories (e.g., Entertainment, Music) have a higher trending probability.\"\n",
    "\n",
    "This hypothesis will be tested using Pearson’s correlation to identify relationships, logistic regression for classification, and probabilistic reasoning to estimate the likelihood of trending under varying conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Understanding\n",
    "We loaded the YouTube dataset and explored its structure, including basic statistics and data types.\n",
    "### Dataset Description\n",
    "The dataset contains information about trending YouTube videos across different countries, including the US, Canada, Germany, and others. It includes various attributes such as video title, channel title, publication date, trending date, views, likes, dislikes, comments, and tags.  It also has categorical data like video category and whether the video includes a thumbnail.\n",
    "\n",
    "The dataset allow us to explore patterns in video performance and understand what factors may contribute to a video becoming trending, such as engagement metrics or metadata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id trending_date  \\\n",
      "0  2kyS6SvSYSE      17.14.11   \n",
      "1  1ZAPwfrtAFY      17.14.11   \n",
      "2  5qpjK5DgCt4      17.14.11   \n",
      "3  puqaWrEC7tY      17.14.11   \n",
      "4  d380meD0W0M      17.14.11   \n",
      "\n",
      "                                               title          channel_title  \\\n",
      "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
      "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
      "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
      "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
      "4                           I Dare You: GOING BALD!?               nigahiga   \n",
      "\n",
      "   category_id              publish_time  \\\n",
      "0           22  2017-11-13T17:13:01.000Z   \n",
      "1           24  2017-11-13T07:30:00.000Z   \n",
      "2           23  2017-11-12T19:05:24.000Z   \n",
      "3           24  2017-11-13T11:00:04.000Z   \n",
      "4           24  2017-11-12T18:01:41.000Z   \n",
      "\n",
      "                                                tags    views   likes  \\\n",
      "0                                    SHANtell martin   748374   57527   \n",
      "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
      "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
      "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
      "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
      "\n",
      "   dislikes  comment_count                                  thumbnail_link  \\\n",
      "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
      "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
      "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
      "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
      "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
      "\n",
      "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
      "0              False             False                   False   \n",
      "1              False             False                   False   \n",
      "2              False             False                   False   \n",
      "3              False             False                   False   \n",
      "4              False             False                   False   \n",
      "\n",
      "                                         description  \n",
      "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
      "1  One year after the presidential election, John...  \n",
      "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
      "3  Today we find out if Link is a Nickelback amat...  \n",
      "4  I know it's been a while since we did this sho...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40949 entries, 0 to 40948\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   video_id                40949 non-null  object\n",
      " 1   trending_date           40949 non-null  object\n",
      " 2   title                   40949 non-null  object\n",
      " 3   channel_title           40949 non-null  object\n",
      " 4   category_id             40949 non-null  int64 \n",
      " 5   publish_time            40949 non-null  object\n",
      " 6   tags                    40949 non-null  object\n",
      " 7   views                   40949 non-null  int64 \n",
      " 8   likes                   40949 non-null  int64 \n",
      " 9   dislikes                40949 non-null  int64 \n",
      " 10  comment_count           40949 non-null  int64 \n",
      " 11  thumbnail_link          40949 non-null  object\n",
      " 12  comments_disabled       40949 non-null  bool  \n",
      " 13  ratings_disabled        40949 non-null  bool  \n",
      " 14  video_error_or_removed  40949 non-null  bool  \n",
      " 15  description             40379 non-null  object\n",
      "dtypes: bool(3), int64(5), object(8)\n",
      "memory usage: 4.2+ MB\n",
      "None\n",
      "        category_id         views         likes      dislikes  comment_count\n",
      "count  40949.000000  4.094900e+04  4.094900e+04  4.094900e+04   4.094900e+04\n",
      "mean      19.972429  2.360785e+06  7.426670e+04  3.711401e+03   8.446804e+03\n",
      "std        7.568327  7.394114e+06  2.288853e+05  2.902971e+04   3.743049e+04\n",
      "min        1.000000  5.490000e+02  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       17.000000  2.423290e+05  5.424000e+03  2.020000e+02   6.140000e+02\n",
      "50%       24.000000  6.818610e+05  1.809100e+04  6.310000e+02   1.856000e+03\n",
      "75%       25.000000  1.823157e+06  5.541700e+04  1.938000e+03   5.755000e+03\n",
      "max       43.000000  2.252119e+08  5.613827e+06  1.674420e+06   1.361580e+06\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = \"youtube-dataset/USvideos.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect data\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "# Display summary statistics\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encapsulation in Classes and Methods\n",
    "We encapsulated the data loading and basic analysis in a class to improve code organization and reusability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def load_json(file_path):\n",
    "  \"\"\"\n",
    "  Load JSON data from a file\n",
    "  :param file_path: path to the JSON file\n",
    "  :return: JSON data\n",
    "  \"\"\"\n",
    "\n",
    "  with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "  return data\n",
    "\n",
    "\n",
    "def convert_raw_categories_to_dict(raw_categories):\n",
    "  \"\"\"\n",
    "  Convert raw categories data to a dictionary\n",
    "  :param raw_categories: raw categories data\n",
    "  :return: categories dictionary\n",
    "  \"\"\"\n",
    "\n",
    "  categories_dict = {}\n",
    "\n",
    "  for item in raw_categories['items']:\n",
    "    categories_dict[int(item['id'])] = item['snippet']['title']\n",
    "\n",
    "  return categories_dict\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self, filepath):\n",
    "        self.data = pd.read_csv(filepath)\n",
    "\n",
    "    def preprocess(self):\n",
    "        # Drop irrelevant or missing data\n",
    "        self.data.dropna(subset=['views', 'likes', 'dislikes', 'comment_count'], inplace=True)\n",
    "        self.data['likes_to_views_ratio'] = self.data['likes'] / self.data['views']\n",
    "        self.data['comments_to_views_ratio'] = self.data['comment_count'] / self.data['views']\n",
    "        return self.data\n",
    "\n",
    "    def summary(self):\n",
    "        print(\"Data Summary:\")\n",
    "        print(self.data.describe())\n",
    "\n",
    "\n",
    "class VideoAnalysis:\n",
    "  \"\"\"\n",
    "  A class to explore the YouTube trending videos dataset\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, file_path):\n",
    "    self.df = pd.read_csv(file_path)\n",
    "\n",
    "  # Method to explore the dataset\n",
    "  def explore_data(self):\n",
    "    \"\"\"\n",
    "    Explore the dataset by displaying column names and summary statistics\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Column Names:\", self.df.columns)\n",
    "    print(\"Dataset Summary:\\n\", self.df.describe())\n",
    "\n",
    "  def data_clean(self):\n",
    "    \"\"\"\n",
    "    Handle missing values.\n",
    "  Convert categorical data into dummy variables.\n",
    "  Convert date fields into Julian dates.\"\"\"\n",
    "    data = self.df.dropna()\n",
    "    # Convert date to Julian\n",
    "    data['publish_date'] = pd.to_datetime(data['publish_time']).dt.date\n",
    "    data['julian_date'] = data['publish_date'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    # Convert categorical columns to dummies\n",
    "    categorical_columns = ['category_id']\n",
    "    data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "    return self.data\n",
    "\n",
    "  def data_transformation(self):\n",
    "    \"\"\"\n",
    "    Box-Cox Transformation: For skewed data like views or likes.\n",
    "    Tukey's Ladder: Apply if needed for outliers.\n",
    "    \"\"\"\n",
    "    # Box-Cox Transformation on 'views'\n",
    "    self.df['views_bc'], _ = boxcox(self.df['views'] + 1)\n",
    "\n",
    "    # Tukey's Ladder on 'likes'\n",
    "    self.df['likes_tukey'], _ = yeojohnson(self.df['likes'] + 1)\n",
    "    return self.df\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['video_id', 'trending_date', 'title', 'channel_title', 'category_id',\n",
      "       'publish_time', 'tags', 'views', 'likes', 'dislikes', 'comment_count',\n",
      "       'thumbnail_link', 'comments_disabled', 'ratings_disabled',\n",
      "       'video_error_or_removed', 'description'],\n",
      "      dtype='object')\n",
      "Dataset Summary:\n",
      "         category_id         views         likes      dislikes  comment_count\n",
      "count  40949.000000  4.094900e+04  4.094900e+04  4.094900e+04   4.094900e+04\n",
      "mean      19.972429  2.360785e+06  7.426670e+04  3.711401e+03   8.446804e+03\n",
      "std        7.568327  7.394114e+06  2.288853e+05  2.902971e+04   3.743049e+04\n",
      "min        1.000000  5.490000e+02  0.000000e+00  0.000000e+00   0.000000e+00\n",
      "25%       17.000000  2.423290e+05  5.424000e+03  2.020000e+02   6.140000e+02\n",
      "50%       24.000000  6.818610e+05  1.809100e+04  6.310000e+02   1.856000e+03\n",
      "75%       25.000000  1.823157e+06  5.541700e+04  1.938000e+03   5.755000e+03\n",
      "max       43.000000  2.252119e+08  5.613827e+06  1.674420e+06   1.361580e+06\n",
      "Data Summary:\n",
      "        category_id         views         likes      dislikes  comment_count  \\\n",
      "count  40949.000000  4.094900e+04  4.094900e+04  4.094900e+04   4.094900e+04   \n",
      "mean      19.972429  2.360785e+06  7.426670e+04  3.711401e+03   8.446804e+03   \n",
      "std        7.568327  7.394114e+06  2.288853e+05  2.902971e+04   3.743049e+04   \n",
      "min        1.000000  5.490000e+02  0.000000e+00  0.000000e+00   0.000000e+00   \n",
      "25%       17.000000  2.423290e+05  5.424000e+03  2.020000e+02   6.140000e+02   \n",
      "50%       24.000000  6.818610e+05  1.809100e+04  6.310000e+02   1.856000e+03   \n",
      "75%       25.000000  1.823157e+06  5.541700e+04  1.938000e+03   5.755000e+03   \n",
      "max       43.000000  2.252119e+08  5.613827e+06  1.674420e+06   1.361580e+06   \n",
      "\n",
      "       likes_to_views_ratio  comments_to_views_ratio  \n",
      "count          40949.000000             40949.000000  \n",
      "mean               0.034413                 0.004453  \n",
      "std                0.027009                 0.005736  \n",
      "min                0.000000                 0.000000  \n",
      "25%                0.014967                 0.001607  \n",
      "50%                0.028273                 0.002961  \n",
      "75%                0.046751                 0.005214  \n",
      "max                0.290466                 0.117643  \n"
     ]
    }
   ],
   "source": [
    "video_analysis = VideoAnalysis(file_path)\n",
    "\n",
    "# Call the method to explore the dataset\n",
    "video_analysis.explore_data()\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "handler = DataHandler(file_path)\n",
    "data = handler.preprocess()\n",
    "handler.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Update\n",
    "The term project aims to analyze YouTube video data to understand trends, user engagement, and content performance. The dataset includes various features such as video titles, publish time, views, likes, dislikes, comment count, and more. The final hypothesis is that certain video attributes (e.g., title length, publish time) significantly impact user engagement metrics (e.g., views, likes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Data Analysis\n",
    "We performed various statistical tests, including Normality, T-test, and Chi-Square tests, to understand the data distribution and relationships.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.26586852271187644, pvalue=6.296434677503596e-148)\n",
      "TtestResult(statistic=5.973831642243304, pvalue=2.6185932588214564e-09, df=2727.0)\n",
      "Chi2ContingencyResult(statistic=801.1345737017033, pvalue=4.877334028605682e-161, dof=15, expected_freq=array([[2.30875040e+03, 3.62496032e+01],\n",
      "       [3.78064031e+02, 5.93596913e+00],\n",
      "       [6.37195419e+03, 1.00045813e+02],\n",
      "       [9.05778407e+02, 1.42215927e+01],\n",
      "       [2.14039376e+03, 3.36062419e+01],\n",
      "       [3.95785782e+02, 6.21421769e+00],\n",
      "       [8.04370607e+02, 1.26293927e+01],\n",
      "       [3.16037901e+03, 4.96209920e+01],\n",
      "       [3.40356082e+03, 5.34391804e+01],\n",
      "       [9.80997397e+03, 1.54026032e+02],\n",
      "       [2.44855532e+03, 3.84446751e+01],\n",
      "       [4.08191008e+03, 6.40899167e+01],\n",
      "       [1.63040113e+03, 2.55988669e+01],\n",
      "       [2.36388473e+03, 3.71152653e+01],\n",
      "       [5.61188796e+01, 8.81120418e-01],\n",
      "       [5.61188796e+01, 8.81120418e-01]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI-venvs\\venv\\Helena_AI_Venv\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:573: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 40949.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Normality test\n",
    "print(stats.shapiro(df['views']))\n",
    "\n",
    "# T-test\n",
    "group1 = df[df['category_id'] == 1]['views']\n",
    "group2 = df[df['category_id'] == 2]['views']\n",
    "print(stats.ttest_ind(group1, group2))\n",
    "\n",
    "# Chi-Square test\n",
    "contingency_table = pd.crosstab(df['category_id'], df['comments_disabled'])\n",
    "print(stats.chi2_contingency(contingency_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction\n",
    "We applied PCA to reduce the dimensionality of the dataset, making it easier to visualize and analyze.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df.select_dtypes(include=[float, int]))\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_df)\n",
    "\n",
    "# Add PCA results to the dataframe\n",
    "df['PCA1'] = pca_result[:, 0]\n",
    "df['PCA2'] = pca_result[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Algorithm Implementation\n",
    "We implemented and displayed results for Clustering, Regression, Classification, and Probabilistic Reasoning algorithms to gain insights from the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.94      0.90      4047\n",
      "        True       0.93      0.87      0.90      4143\n",
      "\n",
      "    accuracy                           0.90      8190\n",
      "   macro avg       0.90      0.90      0.90      8190\n",
      "weighted avg       0.90      0.90      0.90      8190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Clustering\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "df['cluster'] = kmeans.fit_predict(scaled_df)\n",
    "\n",
    "# Regression\n",
    "X = df[['PCA1', 'PCA2']]\n",
    "y = df['views']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Classification\n",
    "df['high_views'] = df['views'] > df['views'].median()\n",
    "X = df[['PCA1', 'PCA2']]\n",
    "y = df['high_views']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Probabilistic Reasoning\n",
    "We used Gaussian Naive Bayes for probabilistic reasoning to predict high view counts based on PCA components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.93      0.78      4047\n",
      "        True       0.89      0.56      0.69      4143\n",
      "\n",
      "    accuracy                           0.75      8190\n",
      "   macro avg       0.79      0.75      0.74      8190\n",
      "weighted avg       0.79      0.75      0.74      8190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Probabilistic Reasoning\n",
    "X = df[['PCA1', 'PCA2']]\n",
    "y = df['high_views']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The analysis provided valuable insights into YouTube video performance and user engagement, supporting our hypothesis.\n",
    "Goal: To understand the factors influencing YouTube video virality and predict whether a video will trend.\n",
    "\n",
    "Findings:\n",
    "\n",
    "Logistic regression and Naïve Bayes models demonstrated that likes_to_views_ratio and comments_to_views_ratio are strong predictors of trending status, with logistic regression achieving higher accuracy (~90%).\n",
    "Future Steps: Refine the model using additional features like video duration and category, and incorporate advanced machine learning techniques for improved predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Helena_AI_Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
